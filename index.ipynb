{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll get some hand-on practice developing a simple linear regression model. You'll also use your model to make a prediction about new data! \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Perform a linear regression using self-constructed functions\n",
    "* Interpret the parameters of a simple linear regression model in relation to what they signify for specific data\n",
    "\n",
    "## Let's get started\n",
    "\n",
    "The best-fit line's slope $\\hat m$ can be calculated as:\n",
    "\n",
    "$$\\hat m = \\rho \\frac{S_Y}{S_X}$$\n",
    "\n",
    "With $\\rho$ being the correlation coefficient and ${S_Y}$ and ${S_X}$ being the standard deviation of $x$ and $y$, respectively. It can be shown that this is also equal to:\n",
    "\n",
    "$$\\hat m = \\dfrac{\\overline{x}*\\overline{y}-\\overline{xy}}{(\\overline{x})^2-\\overline{x^2}}$$\n",
    "\n",
    "You'll use the latter formula in this lab. First, break down the formula into its parts. To do this, you'll import the required libraries and define some data points to work with. Next, you'll use some pre-created toy data in NumPy arrays. Let's do this for you to give you a head start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Initialize arrays X and Y with given values\n",
    "# X = Independent Variable\n",
    "X = np.array([1,2,3,4,5,6,8,8,9,10], dtype=np.float64)\n",
    "# Y = Dependent Variable\n",
    "Y = np.array([7,7,8,9,9,10,10,11,11,12], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a scatter plot of X and Y and comment on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your observations about the relationship between X and Y \n",
    "\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function `calc_slope()`\n",
    "\n",
    "Write a function `calc_slope()` that takes in X and Y and calculates the slope using the formula shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the function to calculate slope as: \n",
    "# (mean(x) * mean(y) â€“ mean(x*y)) / ( mean (x)^2 â€“ mean( x^2))\n",
    "def calc_slope(xs,ys):\n",
    "    \n",
    "    pass\n",
    "\n",
    "calc_slope(X,Y)\n",
    "\n",
    "# 0.5393518518518512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we have our slope. Next we calculate the intercept. \n",
    "\n",
    "As a reminder, the calculation for the best-fit line's y-intercept is:\n",
    "\n",
    "$$\\hat c = \\overline y - \\hat m \\overline x $$\n",
    "\n",
    "\n",
    "## Write a function best_fit()\n",
    "\n",
    "Write a function `best_fit()` that takes in X and Y, calculates the slope and intercept using the formula. The function should return slope and intercept values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the slope function with intercept formula to return calculate slope and intercept from data points\n",
    "\n",
    "def best_fit(xs,ys):\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Uncomment below to test your function\n",
    "\n",
    "#m, c = best_fit(X,Y)\n",
    "#m, c\n",
    "\n",
    "# (0.5393518518518512, 6.379629629629633)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a working model with `m` and `c` as model parameters. We can create a line for the data points using the calculated slope and intercept:\n",
    "\n",
    "* Recall that $y = mx + c$. We can now use slope and intercept values along with X data points (features) to calculate the Y data points (labels) of the regression line. \n",
    "\n",
    "## Write a function reg_line()\n",
    "\n",
    "Write a function `reg_line()` that takes in slope, intercept and X vector and calculates the regression line using $y= mx + c$ for each point in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_line (m, c, xs):\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Uncomment below\n",
    "#regression_line = reg_line(m,c,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the (x,y) data points and draw the calculated regression line for visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data and regression line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there we have it, our least squares regression line. This is the best fit line and does describe the data pretty well (still not perfect though). \n",
    "\n",
    "## Describe your Model Mathematically and in Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting new data\n",
    "\n",
    "So, how might you go about actually making a prediction based on this model you just made?\n",
    "\n",
    "Now that we have a working model with m and b as model parameters. We can fill in a value of x with these parameters to identify a corresponding value of $\\hat y$ according to our model. Recall the formula:\n",
    "\n",
    "$$\\hat y = \\hat mx + \\hat c$$\n",
    "\n",
    "Let's try to find a y prediction for a new value of $x = 7$, and plot the new prediction with existing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = 7\n",
    "y_predicted = None\n",
    "y_predicted\n",
    "\n",
    "# 10.155092592592592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the prediction with the rest of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as above and show the predicted value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know how to create your own models, which is great! Next, you'll find out how to determine the accuracy of your model!\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lesson, you learned how to perform linear regression for data that are linearly related. You first calculated the slope and intercept parameters of the regression line that best fit the data. You then used the regression line parameters to predict the value ($\\hat y$-value) of a previously unseen feature ($x$-value). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
